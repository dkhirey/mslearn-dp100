Azure Introduction -

1. Azure resources created alongside a workspace include:
	A storage account - used to store files used by the workspace as well as data for experiments and model training.
	An Application Insights instance, used to monitor predictive services in the workspace.
	An Azure Key Vault instance, used to manage secrets such as authentication keys and credentials used by the workspace.
	A container registry, created as-needed to manage containers for deployed models.
2. By default, the from_config method looks for a file named config.json in the folder containing the Python code file.
3. The Azure command-line interface (CLI) is a cross-platform command-line tool for managing Azure resources.  (azure-cli-ml)
4. Loggng with Run context -
	log: Record a single named value.
	log_list: Record a named list of values.
	log_row: Record a row with multiple columns.
	log_table: Record a dictionary as a table.
	log_image: Record an image file or a plot.
5. You can run an experiment inline using the start_logging method of the Experiment object.


Datasets -

1. Types of Datastores -
	Azure Storage (blob and file containers)
	Azure Data Lake stores
	Azure SQL Database
	Azure Databricks file system (DBFS)
2. Every workspace has two built-in datastores - 
	Azure Storage blob container, 
	Azure Storage file container
3. The workspace always includes a default datastore initially, this is the built-in workspaceblobstore datastore.
4. Types of Datasets -
	Tabular: The data is read from the dataset as a table. You should use this type of dataset when your data is consistently 	structured and you want to work with it in common tabular data structures, such as Pandas dataframes.
	File: The dataset presents a list of file paths that can be read as though from the file system. Use this type of dataset when your data is unstructured, or when you need to process the data at the file level

Accuracy: (TP+TN)/(TP+TN+FP+FN) - in other words, out all of the predictions, how many were correct?
Recall: TP/(TP+FN) - in other words, of all the cases that are positive, how many did the model identify?
Precision: TP/(TP+FP) - in other words, of all the cases that the model predicted to be positive, how many actually are positive?

Model Explanations -

1. Visualizations are only available for experiment runs that were configured to generate and upload explanations. 
2. When using automated machine learning, only the run producing the best model has explanations generated by default.
3. Visualizing summary importance - You can view the features as a swarm plot, a box plot, or a violin plot.
4. Global feature importance quantifies the relative importance of each feature in the test dataset as a whole.
5. Local feature importance measures the influence of each feature value for a specific individual prediction.
6. For a multi-class classification model, a local importance values for each possible class is calculated for every feature, with the total across all classes always being 0.
7. For a regression model, there are no classes so the local importance values simply indicate the level of influence each feature has on the predicted scalar label.
8. MimicExplainer - An explainer that creates a global surrogate model that approximates your trained model and can be used to generate explanations. This explainable model must have the same kind of architecture as your trained model (for example, linear or tree-based).
9. TabularExplainer - An explainer that acts as a wrapper around various SHAP explainer algorithms, automatically choosing the one that is most appropriate for your model architecture.
10. PFIExplainer - a Permutation Feature Importance explainer that analyzes feature importance by shuffling feature values and measuring the impact on prediction performance.
11. Global Explainer code is the same for MimicExplainer and TabularExplainer. The PFIExplainer requires the actual labels that correspond to the test features.
12. Local Explainer code is the same for MimicExplainer and TabularExplainer. The PFIExplainer doesn't support local feature importance explanations.

Model Fairness -

1. Mitigation algorithms -
    Exponentiated Gradient -A reduction technique that applies a cost-minimization approach to learning the optimal trade-off of overall predictive performance and fairness disparity
    Grid Search - A simplified version of the Exponentiated Gradient algorithm that works efficiently with small numbers of constraints
    Threshold Optimizer - A post-processing technique that applies a constraint to an existing classifier, transforming the prediction as appropriate
2. Demographic parity:this constraint tries to ensure that an equal number of positive predictions are made in each group.
3. True positive rate parity:  this constraint tries to ensure that each group contains a comparable ratio of true positive predictions.
4. False-positive rate parity: this constraint tries to ensure that each group contains a comparable ratio of false-positive predictions.
5. Equalized odds:this constraint tries to ensure that each group contains a comparable ratio of true positive and false-positive predictions.
6. Error rate parity: ensure that the error for each sensitive feature group does not deviate from the overall error rate by more than a specified amount.
7. Bounded group loss: this constraint with any of the reduction-based mitigation algorithms to restrict the loss for each sensitive feature group in a regression model.
8. reduction-based mitigation algorithms - Exponentiated Gradient and Grid Search
9. An important point to reinforce is that applying fairness mitigation to a model is a trade-off between overall predictive performance and disparity across sensitive feature groups

Data Drift -

1. This change in data profiles between training and inferencing is known as data drift
2. You can define a schedule to run every Day, Week, or Month.
3. you can specify a latency, indicating the number of hours to allow for new data to be collected and added to the target dataset
4. Data drift is measured using a calculated magnitude of change in the statistical distribution of feature values over time.
