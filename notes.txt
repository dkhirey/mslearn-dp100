Accuracy: (TP+TN)/(TP+TN+FP+FN) - in other words, out all of the predictions, how many were correct?
Recall: TP/(TP+FN) - in other words, of all the cases that are positive, how many did the model identify?
Precision: TP/(TP+FP) - in other words, of all the cases that the model predicted to be positive, how many actually are positive?

Model Explanations -

1. Visualizations are only available for experiment runs that were configured to generate and upload explanations. 
2. When using automated machine learning, only the run producing the best model has explanations generated by default.
3. Visualizing summary importance - You can view the features as a swarm plot, a box plot, or a violin plot.
4. Global feature importance quantifies the relative importance of each feature in the test dataset as a whole.
5. Local feature importance measures the influence of each feature value for a specific individual prediction.
6. For a multi-class classification model, a local importance values for each possible class is calculated for every feature, with the total across all classes always being 0.
7. For a regression model, there are no classes so the local importance values simply indicate the level of influence each feature has on the predicted scalar label.
8. MimicExplainer - An explainer that creates a global surrogate model that approximates your trained model and can be used to generate explanations. This explainable model must have the same kind of architecture as your trained model (for example, linear or tree-based).
9. TabularExplainer - An explainer that acts as a wrapper around various SHAP explainer algorithms, automatically choosing the one that is most appropriate for your model architecture.
10. PFIExplainer - a Permutation Feature Importance explainer that analyzes feature importance by shuffling feature values and measuring the impact on prediction performance.
11. Global Explainer code is the same for MimicExplainer and TabularExplainer. The PFIExplainer requires the actual labels that correspond to the test features.
12. Local Explainer code is the same for MimicExplainer and TabularExplainer. The PFIExplainer doesn't support local feature importance explanations.

Model Fairness -

1. Mitigation algorithms -
    Exponentiated Gradient -A reduction technique that applies a cost-minimization approach to learning the optimal trade-off of overall predictive performance and fairness disparity
    Grid Search - A simplified version of the Exponentiated Gradient algorithm that works efficiently with small numbers of constraints
    Threshold Optimizer - A post-processing technique that applies a constraint to an existing classifier, transforming the prediction as appropriate
2. Demographic parity:this constraint tries to ensure that an equal number of positive predictions are made in each group.
3. True positive rate parity:  this constraint tries to ensure that each group contains a comparable ratio of true positive predictions.
4. False-positive rate parity: this constraint tries to ensure that each group contains a comparable ratio of false-positive predictions.
5. Equalized odds:this constraint tries to ensure that each group contains a comparable ratio of true positive and false-positive predictions.
6. Error rate parity: ensure that the error for each sensitive feature group does not deviate from the overall error rate by more than a specified amount.
7. Bounded group loss: this constraint with any of the reduction-based mitigation algorithms to restrict the loss for each sensitive feature group in a regression model.
8. reduction-based mitigation algorithms - Exponentiated Gradient and Grid Search
9. An important point to reinforce is that applying fairness mitigation to a model is a trade-off between overall predictive performance and disparity across sensitive feature groups

Data Drift -

1. This change in data profiles between training and inferencing is known as data drift
2. You can define a schedule to run every Day, Week, or Month.
3. you can specify a latency, indicating the number of hours to allow for new data to be collected and added to the target dataset
4. Data drift is measured using a calculated magnitude of change in the statistical distribution of feature values over time.
